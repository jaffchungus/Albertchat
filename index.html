<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Albert Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Arial', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
        }

        .container {
            text-align: center;
            padding: 40px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 20px;
            box-shadow: 0 5px 25px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(10px);
            position: relative;
            width: 90%;
            max-width: 600px;
        }

        h1 {
            font-size: 42px;
            margin-bottom: 20px;
            text-shadow: 0 2px 5px rgba(0, 0, 0, 0.5);
        }

        .status {
            font-size: 20px;
            margin: 20px 0;
            padding: 15px;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            min-height: 60px;
        }

        .loading {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 60px;
            height: 60px;
            border: 6px solid rgba(255, 255, 255, 0.2);
            border-top: 6px solid #00ffcc;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            transform: translate(-50%, -50%);
            display: none;
        }

        @keyframes spin {
            0% { transform: translate(-50%, -50%) rotate(0deg); }
            100% { transform: translate(-50%, -50%) rotate(360deg); }
        }

        .container::before {
            content: '';
            position: absolute;
            inset: 0;
            background: linear-gradient(45deg, rgba(0, 255, 204, 0.1), rgba(255, 0, 102, 0.1));
            border-radius: 20px;
            z-index: -1;
            animation: pulse 3s infinite;
        }

        @keyframes pulse {
            0% { opacity: 0.5; }
            50% { opacity: 0.8; }
            100% { opacity: 0.5; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Albert Chat</h1>
        <div class="status">Say something to start chatting with Albert...</div>
        <div class="loading" id="loading"></div>
    </div>

    <script>
        const API_KEY = "AIzaSyD4m0VHzg-DpEYhsvoEhMRKLBBiW2NcVrE"; // Your confirmed working key
        const status = document.querySelector('.status');
        const loading = document.getElementById('loading');

        let recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        let isAiSpeaking = false;

        recognition.continuous = true;
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        // Gemini API Call with Better Error Handling
        async function getGeminiResponse(text) {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${API_KEY}`;
            const body = {
                contents: [{
                    parts: [{
                        text: text
                    }]
                }]
            };

            try {
                console.log('Sending request to Gemini API with:', text);
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(body)
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }
                const data = await response.json();
                if (!data.candidates || !data.candidates[0].content.parts[0].text) {
                    throw new Error('Invalid response structure');
                }
                const result = data.candidates[0].content.parts[0].text;
                console.log('Gemini response:', result);
                return result;
            } catch (error) {
                console.error('Gemini API Error:', error);
                return "Hey, something went off the rails there. Wanna give it another go?";
            }
        }

        // Text-to-Speech with Super Natural Voice
        function speakResponse(text) {
            console.log('Attempting to speak:', text);
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = speechSynthesis.getVoices();

            if (voices.length === 0) {
                console.error('No voices available yet');
                status.textContent = "Hang on, loading voices...";
                setTimeout(() => speakResponse(text), 500); // Retry after delay
                return;
            }

            // Pick a premium natural voice (e.g., Google or high-quality en-US)
            const naturalVoice = voices.find(voice => 
                voice.name.toLowerCase().includes('google') || 
                voice.name.toLowerCase().includes('natural') || 
                voice.name.toLowerCase().includes('matthew') || 
                (voice.lang === 'en-US' && !voice.name.toLowerCase().includes('robot'))
            ) || voices.find(voice => voice.lang === 'en-US') || voices[0];

            console.log('Selected voice:', naturalVoice ? naturalVoice.name : 'Default');

            utterance.voice = naturalVoice;
            utterance.rate = 1.05;  // Slightly faster than normal for a lively tone
            utterance.pitch = 0.95; // Slightly lower pitch for warmth
            utterance.volume = 1.0;

            // Add natural pauses after punctuation
            const naturalText = text.replace(/([.!?])\s/g, '$1|').split('|').join(' ');
            utterance.text = naturalText;

            isAiSpeaking = true;
            status.textContent = "Alright, here’s my take...";
            loading.style.display = 'block';

            utterance.onstart = () => {
                console.log('Speech started');
                recognition.stop();
            };

            utterance.onend = () => {
                console.log('Speech ended');
                isAiSpeaking = false;
                loading.style.display = 'none';
                status.textContent = "Your turn, what’s up?";
                recognition.start();
            };

            utterance.onerror = (event) => {
                console.error('Speech synthesis error:', event.error);
                isAiSpeaking = false;
                loading.style.display = 'none';
                status.textContent = "Oops, my voice broke. Let’s try that again...";
                recognition.start();
            };

            speechSynthesis.speak(utterance);
        }

        // Speech Recognition Handler
        recognition.onresult = async (event) => {
            if (isAiSpeaking) return;

            const transcript = event.results[event.results.length - 1][0].transcript;
            console.log('Heard:', transcript);
            status.textContent = `You said: ${transcript}`;
            loading.style.display = 'block';

            const response = await getGeminiResponse(transcript);
            loading.style.display = 'none';

            speakResponse(response);
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            if (!isAiSpeaking) {
                status.textContent = "Didn’t catch that, sorry! Try again?";
                setTimeout(() => recognition.start(), 500);
            }
        };

        recognition.onend = () => {
            console.log('Recognition ended');
            if (!isAiSpeaking) {
                recognition.start();
            }
        };

        // Initialization
        function initialize() {
            const voices = speechSynthesis.getVoices();
            console.log('Voices available:', voices.map(v => v.name));
            if (voices.length > 0) {
                status.textContent = "Your turn, what’s up?";
                recognition.start();
            } else {
                speechSynthesis.onvoiceschanged = () => {
                    console.log('Voices loaded:', speechSynthesis.getVoices().map(v => v.name));
                    status.textContent = "Your turn, what’s up?";
                    recognition.start();
                };
            }
        }

        // Start the app
        initialize();
    </script>
</body>
</html>
