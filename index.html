<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Albert Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Arial', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
        }

        .container {
            text-align: center;
            padding: 40px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 20px;
            box-shadow: 0 5px 25px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(10px);
            position: relative;
            width: 90%;
            max-width: 600px;
        }

        h1 {
            font-size: 42px;
            margin-bottom: 20px;
            text-shadow: 0 2px 5px rgba(0, 0, 0, 0.5);
        }

        .status {
            font-size: 20px;
            margin: 20px 0;
            padding: 15px;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            min-height: 60px;
        }

        .loading {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 60px;
            height: 60px;
            border: 6px solid rgba(255, 255, 255, 0.2);
            border-top: 6px solid #00ffcc;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            transform: translate(-50%, -50%);
            display: none;
        }

        @keyframes spin {
            0% { transform: translate(-50%, -50%) rotate(0deg); }
            100% { transform: translate(-50%, -50%) rotate(360deg); }
        }

        .container::before {
            content: '';
            position: absolute;
            inset: 0;
            background: linear-gradient(45deg, rgba(0, 255, 204, 0.1), rgba(255, 0, 102, 0.1));
            border-radius: 20px;
            z-index: -1;
            animation: pulse 3s infinite;
        }

        @keyframes pulse {
            0% { opacity: 0.5; }
            50% { opacity: 0.8; }
            100% { opacity: 0.5; }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Albert Chat</h1>
        <div class="status">Say something to start chatting with Albert...</div>
        <div class="loading" id="loading"></div>
    </div>

    <script>
        const API_KEY = "AIzaSyD4m0VHzg-DpEYhsvoEhMRKLBBiW2NcVrE";
        const status = document.querySelector('.status');
        const loading = document.getElementById('loading');

        let recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        let isAiSpeaking = false;

        recognition.continuous = true;
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        // Gemini API Call
        async function getGeminiResponse(text) {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${API_KEY}`;
            const body = {
                contents: [{
                    parts: [{
                        text: text
                    }]
                }]
            };

            try {
                console.log('Sending request to Gemini API with:', text);
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(body)
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }
                const data = await response.json();
                const result = data.candidates[0].content.parts[0].text;
                console.log('Gemini response:', result);
                return result;
            } catch (error) {
                console.error('Gemini API Error:', error);
                return "Sorry, Albert couldn’t process that. Please try again.";
            }
        }

        // Text-to-Speech with Debugging
        function speakResponse(text) {
            console.log('Attempting to speak:', text);
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = speechSynthesis.getVoices();

            if (voices.length === 0) {
                console.error('No voices available yet');
                status.textContent = "Waiting for voices to load...";
                setTimeout(() => speakResponse(text), 500); // Retry after delay
                return;
            }

            const maleVoice = voices.find(voice => 
                voice.name.toLowerCase().includes('daniel') || 
                voice.name.toLowerCase().includes('david') || 
                voice.name.toLowerCase().includes('matthew') || 
                voice.lang === 'en-US'
            ) || voices[0];

            console.log('Selected voice:', maleVoice ? maleVoice.name : 'Default');

            utterance.voice = maleVoice;
            utterance.rate = 0.9;
            utterance.pitch = 1.0;
            utterance.volume = 1.0;

            isAiSpeaking = true;
            status.textContent = "Albert is speaking...";
            loading.style.display = 'block';

            utterance.onstart = () => {
                console.log('Speech started');
                recognition.stop();
            };

            utterance.onend = () => {
                console.log('Speech ended');
                isAiSpeaking = false;
                loading.style.display = 'none';
                status.textContent = "Listening for you...";
                recognition.start();
            };

            utterance.onerror = (event) => {
                console.error('Speech synthesis error:', event.error);
                isAiSpeaking = false;
                loading.style.display = 'none';
                status.textContent = "Error speaking. Retrying...";
                recognition.start();
            };

            speechSynthesis.speak(utterance);
        }

        // Speech Recognition Handler
        recognition.onresult = async (event) => {
            if (isAiSpeaking) return;

            const transcript = event.results[event.results.length - 1][0].transcript;
            console.log('Heard:', transcript);
            status.textContent = `You said: ${transcript}`;
            loading.style.display = 'block';

            const response = await getGeminiResponse(transcript);
            loading.style.display = 'none';

            speakResponse(response);
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            if (!isAiSpeaking) {
                status.textContent = "Error: Couldn’t hear you. Retrying...";
                setTimeout(() => recognition.start(), 500);
            }
        };

        recognition.onend = () => {
            console.log('Recognition ended');
            if (!isAiSpeaking) {
                recognition.start();
            }
        };

        // Initialization
        function initialize() {
            const voices = speechSynthesis.getVoices();
            console.log('Voices available:', voices.map(v => v.name));
            if (voices.length > 0) {
                status.textContent = "Listening for you...";
                recognition.start();
            } else {
                speechSynthesis.onvoiceschanged = () => {
                    console.log('Voices loaded:', speechSynthesis.getVoices().map(v => v.name));
                    status.textContent = "Listening for you...";
                    recognition.start();
                };
            }
        }

        // Start the app
        initialize();
    </script>
</body>
</html>
